\contentsline {replaced}{Replaced~(harry): \truncate {\Changestruncatewidth }{ Physical time step limiting is enabled with a chosen upper bound $\mathrm \Delta t_{max} = h/50$. In the numerical results, physical time step limiting does not further decrease $\mathrm \Delta t$ from $\mathrm \Delta t_{max}$. }}{17}{section*.4}%
\contentsline {added}{Added~(harry): \truncate {\Changestruncatewidth }{ The accuracy test is conducted using 4th order VFV and 4th order ESDIRK4 time marching. }}{17}{section*.5}%
\contentsline {added}{Added~(harry): \truncate {\Changestruncatewidth }{ Figure \ref {fig:IVres} illustrates density residual convergence history from different accuracy test runs. $N_{it}$ denotes the total inner iteration step across each stage in each ESDIRK step. Every stage in every step lowers residual by nine orders of magnitude. Stage residuals converge faster in finer grids. }}{17}{section*.8}%
\contentsline {added}{Added~(harry): \truncate {\Changestruncatewidth }{4th order VFV and 4th order ESDIRK4}}{18}{section*.7}%
\contentsline {added}{Added~(harry): \truncate {\Changestruncatewidth }{ In addition to accuracy test, efficiency of the current method is compared with a 2nd order counterpart. The 2nd order test uses 2nd order FV and 2nd order trapezoid rule time marching. In the 2nd order scheme, the face flux integration uses midpoint rule. All positivity-preserving algorithms are in the same form. All the tests are conducted on the same machine with the same parameters, and wall time is recorded for each test run. Figure \ref {fig:IVeff} displays convergence and efficiency of the 2nd and 4th order methods. $N_x$ in Figure \ref {fig:IVeff} means number of grids in one direction, or $10/h$ in other words. In Figure \ref {sfig:IVeff_err}, the 4th order method displays 4th or higher order of accuracy, while the 2nd order method displays 2nd order accuracy. On the same $160\times 160$ grid, 4th order method produces only less than $1/100$ of the error 2nd order method produces. Figure \ref {sfig:IVeff_eff} indicates the efficiency of 4th order methods overtakes that of 2nd when the error demand is strict. When $10^{-4}$ density error is needed, 2nd order method uses less time, but when $10^{-6}$ density error is needed, 4th order method uses significantly less time. Therefore, it is demonstrated in the isentropic vortex tests that high order positivity-preserving methods have two advantages: (1) high order methods can resolve the same structure better on the same grid; (2) high order methods consume less time and have higher efficiency when small error is demanded. }}{18}{section*.10}%
\contentsline {added}{Added~(harry): \truncate {\Changestruncatewidth }{ The Le Blanc shock tube problem is a one-dimensional Riemann problem described by the Euler equations and generates an extremely strong shockwave \cite {toro2013riemann}. As a result, the Le Blanc problem is often used as a test case for positivity-preserving schemes \cite {hu2013positivity, chan2021positivity, huang2024general}. The initial conditions are listed in Eq.\eqref {eq:leBlancCond}. }}{18}{section*.12}%
\contentsline {added}{Added~(harry): \truncate {\Changestruncatewidth }{ The ratio of specific heat is $\gamma = 5/3$. The computational domain is in $[0,9]$, partitioned into $N=800$ or $N=3200$ uniform cells. In each inner iteration, the CFL number for local pseudo time step $\text {CFL}_\tau $ is initiated as $0.5$ and increased gradually up to its maximum $10$ at the 10th iteration. The convergence criterion for inner iteration is that the norm of residual decreases by 3 orders of magnitude. For both the $N=800$ and $3200$ grids, two simulations are performed up to $t=6$ using $\mathrm \Delta t_{max} = 0.01$ and $\mathrm \Delta t_{max} = 0.1$ respectively. }}{19}{section*.13}%
\contentsline {added}{Added~(harry): \truncate {\Changestruncatewidth }{ The numerical results of the two simulations are shown in Figure \ref {fig:leBlanc}. It can be observed that the numerical solutions with both time step sizes and both grids basically agree with the exact solution, and no negative values of pressure and density are detected. Positions of the shockwave and contact discontinuity in the finer $N=3200$ grid are significantly closer to the exact solution compared with those in the $N=800$ grid. On both grids, using larger $\mathrm \Delta t_{max}$ produces more oscillations near the shockwave. }}{19}{section*.15}%
\contentsline {added}{Added~(harry): \truncate {\Changestruncatewidth }{ Figure \ref {fig:leBlanc1} illustrates history of time step size and density residual in the Le Blanc problem. Using smaller $\mathrm \Delta t_{max}$, the actual $\mathrm \Delta t$ often reaches $\mathrm \Delta t_{max}=0.01$ on both grids. With larger $\mathrm \Delta t_{max}=0.1$, the actual time step $\mathrm \Delta t$ is constrained by the grid size near strong discontinuities. Figure \ref {sfig:leBlanc1_t} shows that smaller grid size imposes smaller time step size upper bound in physical time step size limiting. }}{19}{section*.17}%
\contentsline {added}{Added~(harry): \truncate {\Changestruncatewidth }{ In Figure \ref {sfig:leBlanc1_res}, the $x$ axis represents total iteration numbers across each stage of each ESDIRK time step. The convergence history shown in Figure \ref {sfig:leBlanc1_res} indicates the residuals reduce rapidly in each stage and step. In a few stages, the residuals struggle to further reduce to 3 orders of magnitude lower than the initial level. Convergence difficulties in these few steps might be the result of oscillations generated in using high order spacial discretization to resolve the extreme discontinuities. }}{19}{section*.18}%
\contentsline {added}{Added~(harry): \truncate {\Changestruncatewidth }{ Numerical results show that the time step limiting procedure does not further decrease the time step here, hence uniform $\mathrm \Delta t$ is observed. }}{20}{section*.19}%
\contentsline {added}{Added~(harry): \truncate {\Changestruncatewidth }{ Figure \ref {fig:DRres} illustrates part of residual convergence history in the rarefaction test. In each stage of each ESDIRK step, it is shown that the solution converges in rather few iterations. }}{20}{section*.21}%
\contentsline {added}{Added~(harry): \truncate {\Changestruncatewidth }{ Time step history and residual convergence history are shown in Figure \ref {fig:sedov1}. Each stage of each step converges rapidly in the inner iterations as shown in Figure \ref {sfig:sedov1_res}. Figure \ref {sfig:sedov1_dt} indicates that the initial Sedov blast leads to strong time step restriction, and with the evolution of the blast, the time step limitation is relaxed until the manual upper bound $\mathrm \Delta t_{max}$ is reached. }}{21}{section*.23}%
\contentsline {added}{Added~(harry): \truncate {\Changestruncatewidth }{ A inviscid Ma 20 flow over a two-dimensional round head is tested in the current subsection following literature that investigated steady state positivity-preserving methods \cite {gallice2022entropy,cossart2025toward}. Although sometimes time-accurate temporal integration is used to obtain a steady state solution, the current test is performed using steady state iteration to illustrate the capability of current algorithm to directly handle steady state computation. In other words, the time-accurate time marching schemes like ESDIRK are replaced with a single implicit Euler step with infinite time step size. All the iterations are in pseudo time and correspond to the inner iterations in the unsteady problems. Therefore, the physical time step limiting is not present in a steady state computation. Pseudo time step limiting, increment correction and polynomial scaling are the same as those in unsteady problems. }}{26}{section*.36}%
\contentsline {added}{Added~(harry): \truncate {\Changestruncatewidth }{ The mesh used in Ma 20 bow shock is a $40\times 100$ structured grid as shown in Figure \ref {sfig:CylinderFront_mesh}. The inflow condition is $(\rho , u, v, p) = (1, 1, 0, 1.78571\times 10^-3)$ and $\gamma =1.4$. Steady calculations are performed using 1st order, 2nd order and 4th order spacial discretizations. The 4th order spacial discretization is 4th order VFV. The 2nd order spacial discretization is 2nd order FV using Green Gauss reconstruction. The 1st order spacial discretization is 1st order FV using piecewise constant reconstruction. The 1st and 2nd order methods use midpoint rule instead of high order quadrature rule. All spacial discretizations still use LLF flux as numerical inviscid flux. }}{28}{section*.37}%
\contentsline {added}{Added~(harry): \truncate {\Changestruncatewidth }{ Convergence history is displayed in Figure \ref {fig:CylinderFront_res}. The 1st order method converges rapidly and the residual decreases to $10^{-8}$ of the peak value within 400 iterations. Residual of the 2nd order method can only converge 5 orders of magnitude, while the 4th order only 3. This troubled convergence is common in shock capturing with 2nd or higher order methods equipped with limiters. }}{28}{section*.39}%
\contentsline {added}{Added~(harry): \truncate {\Changestruncatewidth }{ Density distributions in Figure \ref {fig:CylinderFront} suggest the Ma 20 bow shock can be correctly calculated in all three spacial discretizations. Positivity-preserving algorithms seem not to have affected the quality of converged results. As a result of LLF flux, no carbuncle phenomenon (shock instability) is observed. Width of the shock is rather large in the 1st order result, due to the use of LLF flux. Such smearing is reduced in 2nd and 4th order results. The shock is the sharpest in the 4th order result, and the density peak near stagnation point is also highest in the 4th order result. }}{28}{section*.40}%
\contentsline {added}{Added~(harry): \truncate {\Changestruncatewidth }{ The hypersonic cavity problem \cite {morgenstern1994hypersonic} involves hypersonic air flow over a rectangular cavity on a wall parallel to the flow, modeled with compressible Navier-Stokes equations. Due to the significance of viscosity and hypersonic transient procedures in this problem, the hypersonic cavity is used in the current research to investigate the performance of implicit positivity preserving algorithms. }}{29}{section*.42}%
\contentsline {added}{Added~(harry): \truncate {\Changestruncatewidth }{ Following early computational research \cite {morgenstern1994hypersonic}, we use an inflow condition of $Ma=6.3$, $Re/m=4.084\times 10^6$. Inflow has stagnation temperature $1110\unit {K}$ and wall temperature is $300\unit {K}$. In this test, viscosity obeys standard air's Sutherland's law and Prandtl number is set as $0.72$. The cavity has length-to-depth ratio $L/D=10.67$ and the dimensional depth is $D=19.1\unit {mm}$. In actual computation, inflow densitym, velocity and cavity depth are normalized as $1$. Maximum non-dimensional time step is set to $\mathrm \Delta t_{max}=0.01$ to capture most of the unsteady features according to previous results \cite {morgenstern1994hypersonic}. Although the conditions above are all derived from the reference computation \cite {morgenstern1994hypersonic}, there are still some ambiguities in the computational setup including the inlet velocity profile, the boundary layer mesh height and the choice of time step size, which has not been discussed in the literature to the author's knowledge. }}{29}{section*.43}%
\contentsline {added}{Added~(harry): \truncate {\Changestruncatewidth }{ An unstructured mesh is generated with first layer height being $10^{-4}D$ on the wall. The mesh contains $121,747$ quadrilateral and triangular cells, and is partly displayed in Figure \ref {fig:Cavity_mesh}. The simulation is started with free stream condition and computed until initial transients are eliminated. The 4th order VFV combined with 4th order ESDIRK4 method is used. All positivity-preserving algorithms, including physical time step limiting, pseudo time step limiting, increment correction and reconstruction polynomial scaling are applied. }}{29}{section*.45}%
\contentsline {added}{Added~(harry): \truncate {\Changestruncatewidth }{ After initial transients are eliminated, time-averaged properties are investigated. Figure \ref {fig:Cavity_T} and Figure \ref {fig:Cavity_P} demonstrate time-averaged temperature and pressure distribution. The results generally agree with those from the reference computation \cite {morgenstern1994hypersonic}. To compare the wall heat flux rate and pressure with experimental data \cite {hahn1969experimental}, computed values are normalized with heat transfer rate and pressure at a station $x/D=-1.33$ in Figure \ref {fig:Cavity1}. From Figure \ref {fig:Cavity1}, the computed heat transfer rate matches well with experimental data and reference computation. The variation near the end of the cavity results from large vortex structures, and the experiment might have failed to provide enough resolution \cite {morgenstern1994hypersonic}. The pressure distribution at the bottom of the cavity matches the reference computation, while the experimental pressure values are significantly lower at the start of the cavity. The difference between the current result and the reference computation might be a result of difference in flow condition setups. }}{31}{section*.49}%
\contentsline {added}{Added~(harry): \truncate {\Changestruncatewidth }{ To investigate the profit from using implicit time marching, time steps and projected explicit time steps $\mathrm \Delta t_E$ are plotted in Figure \ref {fig:Cavity_time}. The projected explicit time step size $\mathrm \Delta t_E$ is calculated with criterion $\text {CFL}\leq 1$. Even without any positivity-preserving restrictions, explicit time marching schemes rely on this criterion to maintain linear stability. It can be observed in Figure \ref {fig:Cavity_time} that after initial transients, implicit time step size maintains a value of $0.01$, while $\mathrm \Delta t_E$ stabilizes lower than $1.2\times 10^{-6}$. This means implicit time marching has generally more than $8000$ times larger time steps compared with explicit time marching. Considering that each implicit ESDIRK4 step has 5 stages and each stage takes at most 40 inner iterations to solve, and each implicit inner iteration is at most $20\%$ more expensive than explicit stages according to Table \ref {tab:cpu-time-cost}, the implicit scheme still has efficiency more than 30 times higher than explicit ones. If the cost of multi-stage explicit methods and the time step restriction based on some specific positivity-preserving method are considered, the time step efficiency advantage of the implicit scheme might be even more significant. }}{31}{section*.50}%
